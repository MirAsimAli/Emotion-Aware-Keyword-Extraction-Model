# Emotion-Aware Keyword Extraction Model

## ğŸ“Œ Overview
The **Emotion-Aware Keyword Extraction Model** is an NLP project that performs two key tasks:
1. **Emotion Classification** â€“ Predicts the underlying emotion from a given text input.
2. **Keyword Extraction** â€“ Identifies specific words or phrases in the text that contribute most to the predicted emotion.

This dual approach enables **Explainable AI (XAI)** for sentiment analysis, making the model not just predictive but also interpretable â€” particularly useful for **mental health monitoring, social media analysis, and conversational AI applications**.

---

## ğŸ›  Features
- Emotion detection using **transformer-based architectures** (DistilBERT).
- Keyword extraction for interpretability.
- Hugging Face `Trainer` API for easy training & evaluation.
- Built-in evaluation metrics: Accuracy, Precision, Recall, F1-score.
- Saves fine-tuned model and tokenizer for deployment.

---

## ğŸ“‚ Project Structure
```
Emotion-Aware-Keyword-Extraction-Model/
â”‚
â”œâ”€â”€ emotion_model/             # Saved trained model & tokenizer
â”œâ”€â”€ train_dataset.csv          # Training dataset
â”œâ”€â”€ test_dataset.csv           # Testing dataset
â”œâ”€â”€ train.py                   # Training script for emotion classification
â”œâ”€â”€ keyword_extraction.py      # Script for extracting emotion keywords
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation
```

---

## âš™ï¸ Tech Stack
```python
stack: ["Python", "PyTorch", "Transformers (Hugging Face)", "Pandas", "scikit-learn", "Hugging Face Datasets", "SpaCy/NLTK (for keyword extraction)"]
```

---

## ğŸ“Š Model Architecture
- **Base Model:** `distilbert-base-uncased`
- **Layers:** Transformer encoder â†’ Classification head
- **Output:** 5 emotion labels (configurable)
- **Keyword Extraction:** NER-based + statistical methods (e.g., TF-IDF) to identify contributing terms.

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/MirAsimAli/Emotion-Aware-Keyword-Extraction-Model.git
cd Emotion-Aware-Keyword-Extraction-Model
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Train the Model
```bash
python train.py
```
This will:
- Load datasets (`train_dataset.csv`, `test_dataset.csv`)
- Tokenize & train the model
- Save the fine-tuned model to `./emotion_model`

### 4ï¸âƒ£ Extract Keywords
```bash
python keyword_extraction.py
```

---

## ğŸ“ˆ Evaluation Metrics
The model reports:
- **Accuracy**
- **Precision**
- **Recall**
- **F1 Score**

---

## ğŸ’¡ Example Usage
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_path = "./emotion_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

text = "I feel so anxious about my exam tomorrow."
inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
outputs = model(**inputs)
predicted_label = torch.argmax(outputs.logits, dim=1).item()

print("Predicted Emotion:", predicted_label)
```

---

## ğŸ“œ License
This project is licensed under the MIT License.

---

## ğŸ¤ Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.
